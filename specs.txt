# =====================================================
# INSTALL DEPENDENCIES
# =====================================================
!pip install -q tensorflow tensorflow_hub librosa scikit-learn networkx soundfile

# =====================================================
# IMPORTS
# =====================================================
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import librosa
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import networkx as nx

# =====================================================
# LOAD YAMNET MODEL (FOR AUDIO FEATURE EXTRACTION)
# =====================================================
yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'
yamnet_model = hub.load(yamnet_model_handle)

def extract_features(file_path, sample_rate=16000):
    """Load MP3 and extract YAMNet embeddings"""
    waveform, sr = librosa.load(file_path, sr=sample_rate, mono=True)
    waveform = waveform.astype(np.float32)
    scores, embeddings, spectrogram = yamnet_model(waveform)
    return embeddings.numpy().mean(axis=0)  # mean across frames

# =====================================================
# SINGLE MP3 FILE (YOUR INPUT)
# =====================================================
file_path = "kokki kumar.mp3"  # your MP3 file
feature = extract_features(file_path)

# =====================================================
# DUPLICATE DATA TO CREATE MINI DATASET
# =====================================================
# Creating 4 samples: two of class 0, two of class 1
X = np.array([feature, feature, feature, feature], dtype=np.float32)
y = np.array([0, 0, 1, 1])  # labels for demonstration

# Split dataset into train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# =====================================================
# MLP MODEL
# =====================================================
num_features = X.shape[1]
num_classes = len(np.unique(y))

mlp_model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(num_features,)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train MLP
mlp_model.fit(X_train, y_train, epochs=20, batch_size=2, verbose=1)

# Predict MLP
y_pred_mlp = np.argmax(mlp_model.predict(X_test), axis=1)



# =====================================================
# FINAL PREDICTION (MAJORITY VOTING)
# =====================================================
# Combine MLP and Graph AC predictions
y_pred_final = []
for mlp_pred, graph_pred in zip(y_pred_mlp, y_pred_graph):
    # Majority vote
    if mlp_pred == graph_pred:
        y_pred_final.append(mlp_pred)
    else:
        # If disagreement, randomly pick one (or you can choose MLP priority)
        y_pred_final.append(mlp_pred)  # prioritize MLP here

y_pred_final = np.array(y_pred_final)

# =====================================================
# METRICS CALCULATION
# =====================================================
def compute_metrics(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=1)
    rec = recall_score(y_true, y_pred, zero_division=1)
    f1 = f1_score(y_true, y_pred, zero_division=1)
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0
    return acc, prec, rec, f1, specificity

# =====================================================
# PRINT FINAL METRICS
# =====================================================
acc, prec, rec, f1, spec = compute_metrics(y_test, y_pred_final)
print("=== Final Metrics (MLP  ===")
print(f"Accuracy: {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall: {rec:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Specificity: {spec:.4f}")